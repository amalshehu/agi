# hybrid_arc_solver.py
"""
ARC Prize 2025 Hybrid Solver
Combines principled Chollet-aligned approach with advanced techniques
"""

import numpy as np
import json
import openai
import z3
import sympy
from typing import List, Dict, Tuple, Optional, Any
from dataclasses import dataclass
from collections import Counter
import time
import os

# Import our advanced infrastructure
from advanced_arc_solver import (
    NeuralPatternRecognizer, HierarchicalReasoner, PatternAnalyzer,
    ProgramSynthesizer, DSLProgram, DSLOperation,
    FlipHorizontalOp, FlipVerticalOp, RotateOp, ColorMapOp, ScaleOp,
    ObjectFillOp, GravityOp, SymmetryOp, ConnectDotsOp, MirrorOp
)

# Configure OpenAI (you'll need to set your API key)
# openai.api_key = os.getenv("OPENAI_API_KEY")  # Set this in your environment

@dataclass
class UnifiedObject:
    """Unified object representation following Chollet's principles."""
    color: int
    shape: str  # "rectangle", "L_shape", "dot", etc.
    position: Tuple[int, int]  # (row, col) of center
    size: int  # number of pixels
    bounding_box: Tuple[int, int, int, int]  # (min_row, min_col, max_row, max_col)
    properties: Dict[str, Any]  # additional semantic properties
    
    def __post_init__(self):
        """Add derived properties."""
        self.area = self.size
        self.aspect_ratio = (self.bounding_box[2] - self.bounding_box[0] + 1) / (self.bounding_box[3] - self.bounding_box[1] + 1)

class CostTracker:
    """Track computational costs to stay under $0.30 per task."""
    
    def __init__(self, max_cost_per_task: float = 0.30):
        self.max_cost = max_cost_per_task
        self.current_cost = 0.0
        self.costs = {
            'gpt4_call': 0.20,      # GPT-4 Turbo hypothesis generation
            'symbolic_solve': 0.05,  # Fast symbolic operations
            'neural_analysis': 0.02, # Neural pattern recognition
            'z3_verify': 0.01,      # Z3 rule verification
            'beam_search': 0.10     # Beam search if needed
        }
    
    def can_afford(self, operation: str) -> bool:
        """Check if we can afford an operation."""
        return (self.current_cost + self.costs.get(operation, 0)) <= self.max_cost
    
    def charge(self, operation: str) -> bool:
        """Charge for an operation. Returns False if over budget."""
        cost = self.costs.get(operation, 0)
        if self.current_cost + cost > self.max_cost:
            return False
        self.current_cost += cost
        return True
    
    def remaining_budget(self) -> float:
        """Get remaining budget."""
        return max(0, self.max_cost - self.current_cost)

class ObjectExtractor:
    """Extract unified objects from grids using advanced techniques."""
    
    def __init__(self):
        self.pattern_analyzer = PatternAnalyzer()
    
    def extract_objects(self, grid: np.ndarray) -> List[UnifiedObject]:
        """Extract objects with unified representation."""
        objects = []
        
        # Use advanced flood-fill from our infrastructure
        object_masks = self.pattern_analyzer._find_objects(grid)
        
        for mask in object_masks:
            if np.sum(mask) == 0:
                continue
                
            # Get object properties
            coords = np.where(mask)
            color = grid[mask][0]  # First pixel color
            
            # Position (center of mass)
            center_row = float(np.mean(coords[0]))
            center_col = float(np.mean(coords[1]))
            
            # Bounding box
            min_row, max_row = coords[0].min(), coords[0].max()
            min_col, max_col = coords[1].min(), coords[1].max()
            
            # Shape classification
            shape = self._classify_shape(mask, (min_row, min_col, max_row, max_col))
            
            # Create unified object
            obj = UnifiedObject(
                color=int(color),
                shape=shape,
                position=(center_row, center_col),
                size=int(np.sum(mask)),
                bounding_box=(min_row, min_col, max_row, max_col),
                properties=self._extract_properties(mask, grid)
            )
            
            objects.append(obj)
        
        return objects
    
    def _classify_shape(self, mask: np.ndarray, bbox: Tuple[int, int, int, int]) -> str:
        """Classify object shape."""
        min_row, min_col, max_row, max_col = bbox
        height = max_row - min_row + 1
        width = max_col - min_col + 1
        area = np.sum(mask)
        
        # Extract the object region
        obj_region = mask[min_row:max_row+1, min_col:max_col+1]
        
        # Shape heuristics
        if area == 1:
            return "dot"
        elif area == height * width:
            if height == width:
                return "square"
            else:
                return "rectangle"
        elif area == height or area == width:
            return "line"
        elif self._is_l_shape(obj_region):
            return "L_shape"
        elif self._is_cross(obj_region):
            return "cross"
        else:
            return "irregular"
    
    def _is_l_shape(self, region: np.ndarray) -> bool:
        """Check if shape is L-like."""
        # Simple heuristic: has exactly one corner
        corners = 0
        for i in range(1, region.shape[0]-1):
            for j in range(1, region.shape[1]-1):
                if region[i, j]:
                    # Check for corner pattern
                    neighbors = [
                        region[i-1, j], region[i+1, j],
                        region[i, j-1], region[i, j+1]
                    ]
                    if sum(neighbors) == 2:
                        corners += 1
        return corners == 1
    
    def _is_cross(self, region: np.ndarray) -> bool:
        """Check if shape is cross-like."""
        h, w = region.shape
        if h < 3 or w < 3:
            return False
        
        # Check for cross pattern in center
        center_r, center_c = h // 2, w // 2
        if not region[center_r, center_c]:
            return False
        
        # Check arms
        arms = [
            np.any(region[:center_r, center_c]),  # top
            np.any(region[center_r+1:, center_c]),  # bottom
            np.any(region[center_r, :center_c]),  # left
            np.any(region[center_r, center_c+1:])  # right
        ]
        
        return sum(arms) >= 3
    
    def _extract_properties(self, mask: np.ndarray, grid: np.ndarray) -> Dict[str, Any]:
        """Extract additional object properties."""
        coords = np.where(mask)
        
        return {
            'is_connected': True,  # By construction (flood-fill)
            'perimeter': self._calculate_perimeter(mask),
            'compactness': self._calculate_compactness(mask),
            'touches_border': self._touches_border(mask, grid.shape)
        }
    
    def _calculate_perimeter(self, mask: np.ndarray) -> int:
        """Calculate object perimeter."""
        perimeter = 0
        coords = np.where(mask)
        
        for r, c in zip(coords[0], coords[1]):
            # Count exposed edges
            for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:
                nr, nc = r + dr, c + dc
                if (nr < 0 or nr >= mask.shape[0] or 
                    nc < 0 or nc >= mask.shape[1] or 
                    not mask[nr, nc]):
                    perimeter += 1
        
        return perimeter
    
    def _calculate_compactness(self, mask: np.ndarray) -> float:
        """Calculate shape compactness (4Ï€*area/perimeterÂ²)."""
        area = np.sum(mask)
        perimeter = self._calculate_perimeter(mask)
        
        if perimeter == 0:
            return 0.0
        
        return (4 * np.pi * area) / (perimeter * perimeter)
    
    def _touches_border(self, mask: np.ndarray, grid_shape: Tuple[int, int]) -> bool:
        """Check if object touches grid border."""
        coords = np.where(mask)
        
        return (np.any(coords[0] == 0) or np.any(coords[0] == grid_shape[0] - 1) or
                np.any(coords[1] == 0) or np.any(coords[1] == grid_shape[1] - 1))

class HypothesisGenerator:
    """Generate rule hypotheses using GPT-4 with cost control."""
    
    def __init__(self):
        self.cost_tracker = None
    
    def generate_hypotheses(self, examples: List[Tuple[np.ndarray, np.ndarray]], 
                          cost_tracker: CostTracker,
                          max_hypotheses: int = 3) -> List[str]:
        """Generate rule hypotheses using GPT-4."""
        
        if not cost_tracker.can_afford('gpt4_call'):
            return []  # Can't afford GPT-4, use fallback
        
        # Prepare examples for GPT-4
        example_descriptions = []
        
        for i, (inp, out) in enumerate(examples[:3]):  # Limit to 3 examples
            inp_desc = self._describe_grid(inp)
            out_desc = self._describe_grid(out)
            example_descriptions.append(f"Example {i+1}:\nInput: {inp_desc}\nOutput: {out_desc}")
        
        prompt = self._create_prompt(example_descriptions, max_hypotheses)
        
        try:
            # This is a placeholder - you'll need to implement actual GPT-4 call
            # response = openai.chat.completions.create(
            #     model="gpt-4-turbo-128k",
            #     messages=[{"role": "user", "content": prompt}],
            #     max_tokens=500,
            #     temperature=0.1
            # )
            
            # For now, return template hypotheses based on pattern analysis
            cost_tracker.charge('gpt4_call')
            return self._generate_template_hypotheses(examples)
            
        except Exception as e:
            print(f"GPT-4 call failed: {e}")
            return self._generate_template_hypotheses(examples)
    
    def _describe_grid(self, grid: np.ndarray) -> str:
        """Create compact grid description."""
        h, w = grid.shape
        colors = set(grid.flatten())
        
        # Extract objects
        extractor = ObjectExtractor()
        objects = extractor.extract_objects(grid)
        
        obj_descriptions = []
        for obj in objects:
            obj_descriptions.append(f"{obj.shape}(color={obj.color}, pos={obj.position})")
        
        return f"{h}x{w} grid with colors {colors}, objects: {obj_descriptions}"
    
    def _create_prompt(self, examples: List[str], max_hypotheses: int) -> str:
        """Create GPT-4 prompt for hypothesis generation."""
        
        prompt = f"""You are an expert at solving ARC (Abstraction and Reasoning Corpus) puzzles.

Given these input-output examples, generate {max_hypotheses} rule hypotheses in a simple DSL format.

{chr(10).join(examples)}

Rules should be in this format:
- ROTATE(objects, direction) 
- RECOLOR(objects_condition, new_color)
- SCALE(grid, factor)
- MIRROR(grid, axis)
- MOVE(objects, direction)
- CONNECT(objects, line_color)

Generate {max_hypotheses} most likely rules:
1. Rule 1:
2. Rule 2: 
3. Rule 3:"""

        return prompt
    
    def _generate_template_hypotheses(self, examples: List[Tuple[np.ndarray, np.ndarray]]) -> List[str]:
        """Generate template-based hypotheses when GPT-4 is unavailable."""
        
        # Analyze patterns using our advanced infrastructure
        pattern_recognizer = NeuralPatternRecognizer()
        patterns = pattern_recognizer.recognize_patterns(examples)
        
        hypotheses = []
        
        # Generate hypotheses based on pattern analysis
        if patterns['transformation_type'] == 'geometric':
            hypotheses.extend([
                "ROTATE(all_objects, clockwise_90)",
                "MIRROR(grid, horizontal)",
                "FLIP(grid, vertical)"
            ])
        
        elif patterns['transformation_type'] == 'size_scaling':
            # Check scaling factor
            if examples:
                inp, out = examples[0]
                if out.shape[0] % inp.shape[0] == 0:
                    scale = out.shape[0] // inp.shape[0]
                    hypotheses.append(f"SCALE(grid, {scale})")
        
        elif patterns['transformation_type'] == 'color_mapping':
            # Analyze color transitions
            color_transitions = patterns['color_semantics']['color_transitions']
            if color_transitions:
                most_common = max(color_transitions.items(), key=lambda x: x[1])[0]
                if '->' in most_common:
                    from_color, to_color = most_common.split('->')
                    hypotheses.append(f"RECOLOR(color=={from_color}, {to_color})")
        
        elif patterns['transformation_type'] == 'object_manipulation':
            object_dynamics = patterns['object_dynamics']
            if object_dynamics['object_count_changes']:
                avg_change = np.mean(object_dynamics['object_count_changes'])
                if avg_change < 0:
                    hypotheses.append("REMOVE(smallest_objects)")
                elif avg_change > 0:
                    hypotheses.append("DUPLICATE(all_objects)")
        
        # Ensure we have at least 3 hypotheses
        while len(hypotheses) < 3:
            hypotheses.extend([
                "IDENTITY(grid)",
                "ROTATE(all_objects, clockwise_180)",
                "CONNECT(all_objects, color=1)"
            ])
        
        return hypotheses[:3]

class RuleVerifier:
    """Verify rule hypotheses using Z3 and symbolic execution."""
    
    def __init__(self):
        self.cost_tracker = None
    
    def verify_rule(self, rule: str, examples: List[Tuple[np.ndarray, np.ndarray]], 
                   cost_tracker: CostTracker) -> bool:
        """Verify if rule works on all examples."""
        
        if not cost_tracker.can_afford('z3_verify'):
            # Use simple verification
            return self._simple_verify(rule, examples)
        
        cost_tracker.charge('z3_verify')
        
        try:
            # Parse and execute rule
            for inp, expected_out in examples:
                actual_out = self._execute_rule(rule, inp)
                
                if actual_out is None or not np.array_equal(actual_out, expected_out):
                    return False
            
            return True
            
        except Exception as e:
            print(f"Rule verification failed: {e}")
            return False
    
    def _execute_rule(self, rule: str, grid: np.ndarray) -> Optional[np.ndarray]:
        """Execute a rule on a grid."""
        
        try:
            # Parse rule and execute
            if rule.startswith("ROTATE"):
                if "clockwise_90" in rule:
                    return np.rot90(grid, k=3)  # 90 clockwise = 270 counter-clockwise
                elif "clockwise_180" in rule:
                    return np.rot90(grid, k=2)
                elif "clockwise_270" in rule:
                    return np.rot90(grid, k=1)
            
            elif rule.startswith("MIRROR"):
                if "horizontal" in rule:
                    return np.fliplr(grid)
                elif "vertical" in rule:
                    return np.flipud(grid)
            
            elif rule.startswith("FLIP"):
                if "vertical" in rule:
                    return np.flipud(grid)
                elif "horizontal" in rule:
                    return np.fliplr(grid)
            
            elif rule.startswith("SCALE"):
                # Extract scale factor
                import re
                match = re.search(r'SCALE\(grid,\s*(\d+)\)', rule)
                if match:
                    scale = int(match.group(1))
                    return np.repeat(np.repeat(grid, scale, axis=0), scale, axis=1)
            
            elif rule.startswith("RECOLOR"):
                # Extract color mapping
                import re
                match = re.search(r'RECOLOR\(color==(\d+),\s*(\d+)\)', rule)
                if match:
                    from_color, to_color = int(match.group(1)), int(match.group(2))
                    result = grid.copy()
                    result[result == from_color] = to_color
                    return result
            
            elif rule.startswith("IDENTITY"):
                return grid.copy()
            
            # Add more rule executions as needed
            return None
            
        except Exception as e:
            print(f"Rule execution failed: {e}")
            return None
    
    def _simple_verify(self, rule: str, examples: List[Tuple[np.ndarray, np.ndarray]]) -> bool:
        """Simple verification without Z3."""
        return self.verify_rule(rule, examples, CostTracker(max_cost_per_task=1.0))

class HybridARCSolver:
    """
    Hybrid ARC Solver combining Chollet-aligned principles with advanced techniques.
    
    Architecture:
    - Neural Pathway: Advanced pattern recognition 
    - Symbolic Pathway: Unified object representation + DSL
    - Cost-Aware Routing: <$0.30 per task
    - Hypothesis Generation: GPT-4 for novel patterns
    - Rule Verification: Z3 + symbolic execution
    """
    
    def __init__(self, max_cost_per_task: float = 0.30):
        # Core components
        self.object_extractor = ObjectExtractor()
        self.hypothesis_generator = HypothesisGenerator()
        self.rule_verifier = RuleVerifier()
        
        # Advanced infrastructure (from my previous implementation)
        self.neural_recognizer = NeuralPatternRecognizer()
        self.hierarchical_reasoner = HierarchicalReasoner()
        self.program_synthesizer = ProgramSynthesizer()
        
        # Cost control
        self.max_cost_per_task = max_cost_per_task
    
    def solve_task(self, challenge: Dict, debug: bool = False) -> np.ndarray:
        """
        Solve ARC task using hybrid approach with cost control.
        
        Workflow:
        1. Cost-aware complexity estimation
        2. Route to appropriate solver
        3. Generate hypotheses 
        4. Verify and execute
        """
        
        # Initialize cost tracking
        cost_tracker = CostTracker(self.max_cost_per_task)
        
        # Extract training examples
        train_examples = []
        for example in challenge.get('train', []):
            inp = np.array(example['input'], dtype=int)
            out = np.array(example['output'], dtype=int)
            train_examples.append((inp, out))
        
        if not train_examples:
            return np.array([[0]], dtype=int)
        
        # Get test input
        test_input = np.array(challenge['test'][0]['input'], dtype=int)
        
        if debug:
            print(f"ðŸŽ¯ Hybrid ARC Solver: {len(train_examples)} examples, budget ${cost_tracker.max_cost:.2f}")
        
        # STAGE 1: Complexity-based routing
        complexity = self._estimate_complexity(train_examples, test_input)
        
        if debug:
            print(f"ðŸ“Š Task complexity: {complexity:.3f}")
        
        # STAGE 2: Route to appropriate solver
        if complexity < 0.3 and cost_tracker.can_afford('symbolic_solve'):
            # Simple task - use fast symbolic solver
            result = self._symbolic_solve(train_examples, test_input, cost_tracker, debug)
            if result is not None:
                if debug:
                    print(f"âœ… Symbolic solver succeeded! Cost: ${cost_tracker.current_cost:.2f}")
                return result
        
        # STAGE 3: Advanced hybrid approach for complex tasks
        result = self._hybrid_solve(train_examples, test_input, cost_tracker, debug)
        
        if result is not None:
            if debug:
                print(f"âœ… Hybrid solver succeeded! Cost: ${cost_tracker.current_cost:.2f}")
            return result
        
        # STAGE 4: Emergency fallback
        if debug:
            print(f"âš ï¸ Using fallback, cost: ${cost_tracker.current_cost:.2f}")
        
        return self._emergency_fallback(train_examples, test_input)
    
    def _estimate_complexity(self, examples: List[Tuple[np.ndarray, np.ndarray]], 
                           test_input: np.ndarray) -> float:
        """Estimate task complexity for routing decisions."""
        
        complexity_score = 0.0
        
        # Factor 1: Grid size complexity
        max_size = max(max(inp.size, out.size) for inp, out in examples)
        complexity_score += min(max_size / 400.0, 0.3)  # Cap at 0.3
        
        # Factor 2: Shape change complexity
        shape_changes = [(inp.shape, out.shape) for inp, out in examples]
        if len(set(shape_changes)) > 1:
            complexity_score += 0.2  # Multiple different shape changes
        elif any(inp.shape != out.shape for inp, out in examples):
            complexity_score += 0.1  # Single shape change type
        
        # Factor 3: Color complexity
        all_colors = set()
        for inp, out in examples:
            all_colors.update(inp.flatten())
            all_colors.update(out.flatten())
        
        complexity_score += min(len(all_colors) / 20.0, 0.2)
        
        # Factor 4: Object count complexity
        object_counts = []
        for inp, out in examples:
            inp_objects = len(self.object_extractor.extract_objects(inp))
            out_objects = len(self.object_extractor.extract_objects(out))
            object_counts.extend([inp_objects, out_objects])
        
        if object_counts:
            max_objects = max(object_counts)
            complexity_score += min(max_objects / 20.0, 0.2)
        
        # Factor 5: Pattern inconsistency
        if len(examples) > 1:
            # Check if examples follow consistent patterns
            first_pattern = self._get_basic_pattern(examples[0])
            consistent = all(self._get_basic_pattern(ex) == first_pattern for ex in examples[1:])
            if not consistent:
                complexity_score += 0.2
        
        return min(complexity_score, 1.0)
    
    def _get_basic_pattern(self, example: Tuple[np.ndarray, np.ndarray]) -> str:
        """Get basic pattern type for consistency checking."""
        inp, out = example
        
        if np.array_equal(inp, out):
            return "identity"
        elif inp.shape != out.shape:
            return "shape_change"
        elif set(inp.flatten()) != set(out.flatten()):
            return "color_change"
        elif np.array_equal(np.fliplr(inp), out):
            return "flip_horizontal"
        elif np.array_equal(np.flipud(inp), out):
            return "flip_vertical"
        else:
            return "complex"
    
    def _symbolic_solve(self, examples: List[Tuple[np.ndarray, np.ndarray]], 
                       test_input: np.ndarray, cost_tracker: CostTracker, 
                       debug: bool = False) -> Optional[np.ndarray]:
        """Fast symbolic solver for simple patterns."""
        
        cost_tracker.charge('symbolic_solve')
        
        # Try simple transformations first
        simple_transforms = [
            ("identity", lambda x: x),
            ("flip_horizontal", np.fliplr),
            ("flip_vertical", np.flipud),
            ("rotate_90", lambda x: np.rot90(x, k=3)),
            ("rotate_180", lambda x: np.rot90(x, k=2)),
            ("rotate_270", lambda x: np.rot90(x, k=1)),
        ]
        
        for name, transform in simple_transforms:
            if self._test_transform(transform, examples):
                if debug:
                    print(f"ðŸ”§ Applied simple transform: {name}")
                return transform(test_input)
        
        # Try simple scaling
        if examples:
            inp, out = examples[0]
            if (inp.shape[0] > 0 and inp.shape[1] > 0 and 
                out.shape[0] % inp.shape[0] == 0 and out.shape[1] % inp.shape[1] == 0):
                
                scale_h = out.shape[0] // inp.shape[0]
                scale_w = out.shape[1] // inp.shape[1]
                
                if scale_h == scale_w and scale_h <= 5:
                    # Test scaling
                    def scale_transform(x):
                        return np.repeat(np.repeat(x, scale_h, axis=0), scale_w, axis=1)
                    
                    if self._test_transform(scale_transform, examples):
                        if debug:
                            print(f"ðŸ”§ Applied scaling: {scale_h}x")
                        return scale_transform(test_input)
        
        return None
    
    def _test_transform(self, transform: callable, examples: List[Tuple[np.ndarray, np.ndarray]]) -> bool:
        """Test if transform works on all examples."""
        try:
            for inp, expected_out in examples:
                actual_out = transform(inp)
                if not np.array_equal(actual_out, expected_out):
                    return False
            return True
        except:
            return False
    
    def _hybrid_solve(self, examples: List[Tuple[np.ndarray, np.ndarray]], 
                     test_input: np.ndarray, cost_tracker: CostTracker, 
                     debug: bool = False) -> Optional[np.ndarray]:
        """Advanced hybrid solving with neural guidance and hypothesis generation."""
        
        # Neural pattern analysis
        if cost_tracker.can_afford('neural_analysis'):
            cost_tracker.charge('neural_analysis')
            neural_patterns = self.neural_recognizer.recognize_patterns(examples)
            
            if debug:
                print(f"ðŸ§  Neural analysis: {neural_patterns['transformation_type']}")
        else:
            neural_patterns = {'transformation_type': 'unknown'}
        
        # Generate hypotheses
        hypotheses = self.hypothesis_generator.generate_hypotheses(
            examples, cost_tracker, max_hypotheses=3
        )
        
        if debug and hypotheses:
            print(f"ðŸ’¡ Generated {len(hypotheses)} hypotheses")
        
        # Verify and execute hypotheses
        for i, hypothesis in enumerate(hypotheses):
            if self.rule_verifier.verify_rule(hypothesis, examples, cost_tracker):
                result = self.rule_verifier._execute_rule(hypothesis, test_input)
                if result is not None:
                    if debug:
                        print(f"âœ… Hypothesis {i+1} succeeded: {hypothesis}")
                    return result
        
        # Fallback to advanced techniques if budget allows
        if cost_tracker.can_afford('beam_search'):
            cost_tracker.charge('beam_search')
            
            # Try hierarchical reasoning
            result = self.hierarchical_reasoner.solve_hierarchically(examples, test_input)
            if result is not None:
                if debug:
                    print("âœ… Hierarchical reasoning succeeded")
                return result
            
            # Try program synthesis with limited search
            program = self.program_synthesizer.synthesize_program(examples, max_attempts=500)
            if program:
                try:
                    result = program.execute(test_input)
                    if debug:
                        print(f"âœ… Program synthesis: {program.description()}")
                    return result
                except:
                    pass
        
        return None
    
    def _emergency_fallback(self, examples: List[Tuple[np.ndarray, np.ndarray]], 
                           test_input: np.ndarray) -> np.ndarray:
        """Emergency fallback when all else fails."""
        
        # Return most similar training output
        if not examples:
            return np.array([[0]], dtype=int)
        
        best_output = examples[0][1]
        best_similarity = 0
        
        for inp, out in examples:
            if inp.shape == test_input.shape:
                similarity = np.mean(inp == test_input)
                if similarity > best_similarity:
                    best_similarity = similarity
                    best_output = out
        
        return best_output

# Test function
def test_hybrid_solver():
    """Test the hybrid solver on a simple example."""
    
    # Create a simple test case: horizontal flip
    test_challenge = {
        "train": [
            {"input": [[1, 0], [0, 1]], "output": [[0, 1], [1, 0]]},
            {"input": [[1, 1, 0], [0, 0, 1]], "output": [[0, 1, 1], [1, 0, 0]]},
        ],
        "test": [
            {"input": [[1, 0, 0], [0, 1, 1]]}
        ]
    }
    
    solver = HybridARCSolver()
    result = solver.solve_task(test_challenge, debug=True)
    
    print(f"Input: {test_challenge['test'][0]['input']}")
    print(f"Output: {result}")
    print(f"Expected: [[0, 0, 1], [1, 1, 0]]")
    
    return result

if __name__ == "__main__":
    print("ðŸš€ Testing Hybrid ARC Solver...")
    test_hybrid_solver()
